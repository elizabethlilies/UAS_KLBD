{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elizabethlilies/UAS_KLBD_Elizabeth2206014731/blob/main/colab2_User_basedCollaborativeFiltering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q29FLafm8mD"
      },
      "source": [
        "<center> <b> 2. User-Based Collaborating Filtering </b> </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO2SBOc0m8mJ"
      },
      "source": [
        "### Download tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Y0yIlNlum8mJ"
      },
      "outputs": [],
      "source": [
        "#mengekstrak folder yang didalamnya terdaoat data yang akan dikerjakan\n",
        "import os\n",
        "\n",
        "if not (os.path.exists(\"recsys.zip\") or os.path.exists(\"recsys\")):\n",
        "    !wget https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip    \n",
        "    !unzip recsys.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbEBWYP7m8mL"
      },
      "source": [
        "### Import requirements\n",
        "```\n",
        "matplotlib==3.2.2\n",
        "numpy==1.19.2\n",
        "pandas==1.0.5\n",
        "python==3.7\n",
        "scikit-learn==0.24.1\n",
        "scikit-surprise==1.1.1\n",
        "scipy==1.6.2\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4ccLMVy3m8mL"
      },
      "outputs": [],
      "source": [
        "#menyiapkan library yang akan digunakan\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "from recsys.datasets import ml100k\n",
        "from recsys.preprocessing import ids_encoder\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i3CA_v8m8mM"
      },
      "source": [
        "### Load MovieLen ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8IYkGd4Fm8mM"
      },
      "outputs": [],
      "source": [
        "#mengunduh data\n",
        "ratings, movies = ml100k.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19rbWyt0m8mN"
      },
      "source": [
        "### userids and itemids encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "JW5f5DR7m8mR"
      },
      "outputs": [],
      "source": [
        "# membuat penyandi/ pembuat kode\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iJk0mQlm8mT"
      },
      "source": [
        "### Transform rating dataframe to matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "KOyr8GcQm8mU"
      },
      "outputs": [],
      "source": [
        "def ratings_matrix(ratings):    \n",
        "    return csr_matrix(pd.crosstab(ratings.userid, ratings.itemid, ratings.rating, aggfunc=sum).fillna(0).values)    \n",
        "\n",
        "R = ratings_matrix(ratings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv4enm2Xm8mV"
      },
      "source": [
        "# Memory based collaborative filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLl6IMdgm8mV"
      },
      "source": [
        "Memory based collaborative filtering (CF) also known as nearest neighbors based CF makes recommendation based on similar behavious of users and items. There are two types of memory based CF : <b>user-based</b> and <b>item-based</b> CF. Both of these algorithm usually proceed in three stages :\n",
        "\n",
        "1. Similarity computation (between users or items)\n",
        "2. Rating prediction (using ratings of similar users or items)\n",
        "3. Top-N recommendation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a-3Lk-Jm8mV"
      },
      "source": [
        "# 1. User-based Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDXcEfyFm8mW"
      },
      "source": [
        "## Idea\n",
        "\n",
        "Let $u$ be the user for which we plan to make recommendations. \n",
        "\n",
        "1. Find other users whose past rating behavior is similar to that of $u$\n",
        "2. Use their ratings on other items to predict what the current user will like"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3dPhJVAm8mW"
      },
      "source": [
        "## Algorithm : user-to-user collaborative filtering\n",
        "\n",
        "The entire process of user-to-user CF algorithm is described as follow <a href=\"https://romisatriawahono.net/lecture/rm/survey/information%20retrieval/Bobadilla%20-%20Recommender%20Systems%20-%202013.pdf\">(J. Bobadilla et al. 2013)</a>: For an active user $u$,\n",
        "\n",
        "<ol>\n",
        "    <li> First identify the set $G_u$ of $k$ most similar users. $G_u$ is the group users similar to the active user $u$. The similarity between two users $u$ and $v$ can be measured by the cosine similarity measure as follows :\n",
        "\n",
        "\\begin{equation}\n",
        " w_{u,v}=\\frac{\\vec{r}_u \\cdot \\vec{r}_v}{\\|\\vec{r}_u\\|_2 \\ast \\|\\vec{r}_v\\|_2} = \\frac{\\sum_{i\\in I}r_{u,i}r_{v,i}}{\\sqrt{\\sum_{i\\in I} (r_{u,i})^2}\\sqrt{\\sum_{i\\in I} (r_{v,i})^2}}\n",
        "\\end{equation}\n",
        "\n",
        "$w_{u,v}$ is the degree of similarity between users $u$ and $v$. This term is computed for all $v\\in U$, where $U$ is the set of all users. There remains the question of how many neighbors to select. As experimented by <a href=\"https://dl.acm.org/doi/10.1145/3130348.3130372\">(Herlocker et al. 1999)</a>, $k\\in [20,50]$ is a reasonable starting point in many domains.\n",
        "    </li>\n",
        "    <li> Find the set $C$ of candidate items, purchased by the group and not purchased by the active user $u$. Candidate items have to be the most frequent items purchased by the group.\n",
        "    </li>\n",
        "    <li>Aggregate ratings of users in $G_u$ to make predictions for user $u$ on items he has not already purchased. Several aggregation approaches are often used such as <b>average, weighted sum, ajusted weighted sum</b>. By using weighted sum, the predicted rating of user $u$ on item $i$ denoted by $\\hat{r}_{u,i}$ is computed as follow :\n",
        "\n",
        "\\begin{equation}\n",
        " \\hat{r}_{u,i}=\\bar{r}_u + \\frac{\\sum_{v\\in G_u}(r_{v,i}-\\bar{r}_v)\\cdot w_{u,v}}{\\sum_{v\\in G_u}|w_{u,v}|}.\n",
        "\\end{equation}\n",
        "\n",
        "Ratings of similar users are weighted by the corresponding similarity with the active user. Summation are made over all the users who have rated item $i$. Subtracting the user’s mean rating $\\bar{r}_v$ compensates for differences in users’ use of the rating scale as some users will tend to give higher ratings than others <a href=\"https://dl.acm.org/doi/10.1561/1100000009\">(Michael D. Ekstrand, <i>et al.</i> 2011)</a>. This prediction is made for all items $i \\in C$ not purchased by user $u$.\n",
        "    </li>\n",
        "    <li>The Top-$N$ recommendations are obtained by choosing the $N$ items which provide most satisfaction to the user according to prediction.\n",
        "    </li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm4SbBu-m8mX"
      },
      "source": [
        "### Step 1. Identify $G_u$, the set of $k$ users similar to an active user $u$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-Rg2CCBm8mX"
      },
      "source": [
        "To find the $k$ most similar users to $u$, we use the cosine similarity and compute $w_{u,v}$ for all $v\\in U$. Fortunately, libraries such as <i>scikit-learn (sklearn)</i> are very useful for such tasks :\n",
        "\n",
        "1. First of all, we create a nearest neighbors model with sklearn through the function ```create_model()```. This function creates and fit a nearest neighbors model with user's ratings. We can choose ```cosine``` or ```euclidian``` based similarity metric. ```n_neighbors=21``` define the number of neighbors to return. With $k=20$ neighbors, $|G_u|=21$ as $G_u$ contains $20$ similar users added to the active user $u$. That is why ```n_neighbors=21```. Each row $r_u$ of the rating matrix $R$ represents ratings of user $u$ on all items of the database. Missing ratings are replaced with $0.0$. \n",
        "```python\n",
        "R[u,:] # uth row of the rating matrix R. Ratings of user u on all items in the database\n",
        "```\n",
        "2. Function ```nearest_neighbors()``` returns the knn users for each user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "OBrV6-jKm8mY"
      },
      "outputs": [],
      "source": [
        "def create_model(rating_matrix, metric):\n",
        "    \"\"\"\n",
        "    - create the nearest neighbors model with the corresponding similarity metric\n",
        "    - fit the model\n",
        "    \"\"\"\n",
        "    model = NearestNeighbors(metric=metric, n_neighbors=21, algorithm='brute')\n",
        "    model.fit(rating_matrix)    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "AWR9PntCm8mY"
      },
      "outputs": [],
      "source": [
        "def nearest_neighbors(rating_matrix, model):\n",
        "    \"\"\"    \n",
        "    :param rating_matrix : rating matrix of shape (nb_users, nb_items)\n",
        "    :param model : nearest neighbors model    \n",
        "    :return\n",
        "        - similarities : distances of the neighbors from the referenced user\n",
        "        - neighbors : neighbors of the referenced user in decreasing order of similarities\n",
        "    \"\"\"    \n",
        "    similarities, neighbors = model.kneighbors(rating_matrix)        \n",
        "    return similarities[:, 1:], neighbors[:, 1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CxoAfmVm8mZ"
      },
      "source": [
        "Let's call functions ```create_model()``` and ```nearest_neighbors()``` to respectively create the $k$-NN model and compute the nearest neighbors for a given user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "EmSEEXznm8mZ"
      },
      "outputs": [],
      "source": [
        "model = create_model(rating_matrix=R, metric='cosine') # we can also use the 'euclidian' distance\n",
        "similarities, neighbors = nearest_neighbors(R, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1n7LHxPm8mZ"
      },
      "source": [
        "### Step 2. Find candidate items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToDiG88Mm8ma"
      },
      "source": [
        "The set $C$ of candidate items are the most frequent ones purchased by users in $G_u$ for an active user $u$ and not purchased by $u$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHawbFY8m8ma"
      },
      "source": [
        "Function ```find_candidate_items()``` : find items purchased by these similar users as well as their frequency. Note that the frequency of the items in the set $C$ can be computed by just counting the actual occurrence frequency of that items.\n",
        "\n",
        "1. ```Gu_items``` : frequent items of $G_u$ in decreasing order of frequency.\n",
        "2. ```active_items``` : items already purchased by the active user\n",
        "3. ```candidates``` : frequent items of $G_u$ not purchased by the active user $u$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ihTQlVkPm8ma"
      },
      "outputs": [],
      "source": [
        "def find_candidate_items(userid):\n",
        "    \"\"\"\n",
        "    Find candidate items for an active user\n",
        "    \n",
        "    :param userid : active user\n",
        "    :param neighbors : users similar to the active user        \n",
        "    :return candidates : top 30 of candidate items\n",
        "    \"\"\"\n",
        "    user_neighbors = neighbors[userid]\n",
        "    activities = ratings.loc[ratings.userid.isin(user_neighbors)]\n",
        "    \n",
        "    # mengurutkan item dalam urutan frekuensi tertinggi ke terendah\n",
        "    frequency = activities.groupby('itemid')['rating'].count().reset_index(name='count').sort_values(['count'],ascending=False)\n",
        "    Gu_items = frequency.itemid\n",
        "    active_items = ratings.loc[ratings.userid == userid].itemid.to_list()\n",
        "    candidates = np.setdiff1d(Gu_items, active_items, assume_unique=True)[:30]\n",
        "        \n",
        "    return candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO7zsT5km8ma"
      },
      "source": [
        "### Step 3. Rating prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO47Cs26m8mb"
      },
      "source": [
        "Now it's time to predict what score the active user $u$ would have given to each of the top-30 candidate items.\n",
        "\n",
        "To predict the score of $u$ on a candidate item $i$ ,we need :\n",
        "1. Similarities between $u$ and all his neighbors $v \\in G_u$ who rated item $i$ : function ```nearest_neighbors()``` returns similar users of a user as well as their corresponding similarities.\n",
        "2. Normalized ratings of all $v \\in G_u$ on item $i$. The normalized rating of user $v$ on item $i$ is defined by $r_{v,i}-\\bar{r}_v$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vou6j_rQm8mb"
      },
      "source": [
        "Next, let's compute the mean rating of each user and the normalized ratings for each item. The DataFrame ```mean``` contains mean rating for each user. With the mean rating of each user, we can add an extra column ```norm_rating``` to the ```ratings```'s DataFrame which can be accessed to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "UsBwIFEsm8mb"
      },
      "outputs": [],
      "source": [
        "# rata-rata peringkat pada masing-masing pengguna\n",
        "mean = ratings.groupby(by='userid', as_index=False)['rating'].mean()\n",
        "mean_ratings = pd.merge(ratings, mean, suffixes=('','_mean'), on='userid')\n",
        "\n",
        "# normalisasi peringkat pada masing-masing item\n",
        "mean_ratings['norm_rating'] = mean_ratings['rating'] - mean_ratings['rating_mean']\n",
        "\n",
        "mean = mean.to_numpy()[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "zIsDYfxBm8mc"
      },
      "outputs": [],
      "source": [
        "np_ratings = mean_ratings.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKU3BgjYm8mc"
      },
      "source": [
        "Let us define function ```predict``` that predict rating between user $u$ and item $i$. Recall that the prediction formula is defined as follow :\n",
        "\n",
        "\\begin{equation}\n",
        " \\hat{r}_{u,i}=\\bar{r}_u + \\frac{\\sum_{v\\in G_u}(r_{v,i}-\\bar{r}_v)\\cdot w_{u,v}}{\\sum_{v\\in G_u}|w_{u,v}|}.\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "FAMxhSuBm8mc"
      },
      "outputs": [],
      "source": [
        "def predict(userid, itemid):\n",
        "    \"\"\"\n",
        "    predict what score userid would have given to itemid.\n",
        "    \n",
        "    :param\n",
        "        - userid : user id for which we want to make prediction\n",
        "        - itemid : item id on which we want to make prediction\n",
        "        \n",
        "    :return\n",
        "        - r_hat : predicted rating of user userid on item itemid\n",
        "    \"\"\"\n",
        "    user_similarities = similarities[userid]\n",
        "    user_neighbors = neighbors[userid]\n",
        "    # memperoleh rata-rata rating berdasarkan pengguna 'userid'\n",
        "    user_mean = mean[userid]\n",
        "    \n",
        "    # menemukan pengguna yang memberikan rating pada item 'itemid'\n",
        "    iratings = np_ratings[np_ratings[:, 1].astype('int') == itemid]\n",
        "    \n",
        "    # menemukan pengguna 'userid' yang mirip yang memberikan rating item 'itemid'\n",
        "    suri = iratings[np.isin(iratings[:, 0], user_neighbors)]\n",
        "    \n",
        "    # pengguna yang mirip yang memberikan rating item saat ini (surci)\n",
        "    normalized_ratings = suri[:,4]\n",
        "    indexes = [np.where(user_neighbors == uid)[0][0] for uid in suri[:, 0].astype('int')]\n",
        "    sims = user_similarities[indexes]\n",
        "    \n",
        "    num = np.dot(normalized_ratings, sims)\n",
        "    den = np.sum(np.abs(sims))\n",
        "    \n",
        "    if num == 0 or den == 0:\n",
        "        return user_mean\n",
        "    \n",
        "    r_hat = user_mean + np.dot(normalized_ratings, sims) / np.sum(np.abs(sims))\n",
        "    \n",
        "    return r_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIsTjA0Im8mc"
      },
      "source": [
        "Now, we can make rating prediction for a given user on each item in his set of candidate items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "jZ6LvpCym8md"
      },
      "outputs": [],
      "source": [
        "def user2userPredictions(userid, pred_path):\n",
        "    \"\"\"\n",
        "    Make rating prediction for the active user on each candidate item and save in file prediction.csv\n",
        "    \n",
        "    :param\n",
        "        - userid : id of the active user\n",
        "        - pred_path : where to save predictions\n",
        "    \"\"\"    \n",
        "    # menemukan kandidat item untuk pengguna yang aktif\n",
        "    candidates = find_candidate_items(userid)\n",
        "    \n",
        "    # mengulang item kandidat untuk membuat prediksi\n",
        "    for itemid in candidates:\n",
        "        \n",
        "        # prediksi untuk userid dan itemid\n",
        "        r_hat = predict(userid, itemid)\n",
        "        \n",
        "        # menyimpan prediksi\n",
        "        with open(pred_path, 'a+') as file:\n",
        "            line = '{},{},{}\\n'.format(userid, itemid, r_hat)\n",
        "            file.write(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "IgthookUm8md"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "def user2userCF():\n",
        "    \"\"\"\n",
        "    Make predictions for each user in the database.    \n",
        "    \"\"\"\n",
        "    # memperoleh daftar pengguna dalam database\n",
        "    users = ratings.userid.unique()\n",
        "    \n",
        "    def _progress(count):\n",
        "        sys.stdout.write('\\rRating predictions. Progress status : %.1f%%' % (float(count/len(users))*100.0))\n",
        "        sys.stdout.flush()\n",
        "    \n",
        "    saved_predictions = 'predictions.csv'    \n",
        "    if os.path.exists(saved_predictions):\n",
        "        os.remove(saved_predictions)\n",
        "    \n",
        "    for count, userid in enumerate(users):        \n",
        "        # membuat prediksi rating untuk pengguna saat ini\n",
        "        user2userPredictions(userid, saved_predictions)\n",
        "        _progress(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "6GwOaxDBm8md",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f5f59c-c1af-4e7e-e230-5b9cfd099391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rating predictions. Progress status : 99.9%"
          ]
        }
      ],
      "source": [
        "user2userCF()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVUOEv_8m8mg"
      },
      "source": [
        "### Step 4. Top-N recommendation\n",
        "\n",
        "Function ```user2userRecommendation()``` reads predictions for a given user and return the list of items in decreasing order of predicted rating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "yuBsI3-Am8mg"
      },
      "outputs": [],
      "source": [
        "def user2userRecommendation(userid):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    # menyandikan userid\n",
        "    uid = uencoder.transform([userid])[0]\n",
        "    saved_predictions = 'predictions.csv'\n",
        "    \n",
        "    predictions = pd.read_csv(saved_predictions, sep=',', names=['userid', 'itemid', 'predicted_rating'])\n",
        "    predictions = predictions[predictions.userid==uid]\n",
        "    List = predictions.sort_values(by=['predicted_rating'], ascending=False)\n",
        "    \n",
        "    List.userid = uencoder.inverse_transform(List.userid.tolist())\n",
        "    List.itemid = iencoder.inverse_transform(List.itemid.tolist())\n",
        "    \n",
        "    List = pd.merge(List, movies, on='itemid', how='inner')\n",
        "    \n",
        "    return List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "knxss4Gam8mg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "20080f3e-e085-47ed-da72-993c7c4000a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    userid  itemid  predicted_rating  \\\n",
              "0      212      88          5.108297   \n",
              "1      212     167          5.011518   \n",
              "2      212      21          5.011458   \n",
              "3      212     190          4.942885   \n",
              "4      212      81          4.933844   \n",
              "5      212     650          4.838254   \n",
              "6      212     264          4.786985   \n",
              "7      212     182          4.778395   \n",
              "8      212       8          4.763397   \n",
              "9      212      95          4.742200   \n",
              "10     212      86          4.699650   \n",
              "11     212     208          4.666127   \n",
              "12     212     195          4.665243   \n",
              "13     212     214          4.634145   \n",
              "14     212     209          4.632306   \n",
              "15     212     215          4.607459   \n",
              "16     212     152          4.606413   \n",
              "17     212     185          4.605151   \n",
              "18     212     123          4.595540   \n",
              "19     212     227          4.564913   \n",
              "20     212     422          4.559592   \n",
              "21     212      27          4.556769   \n",
              "22     212     236          4.315180   \n",
              "23     212      57          4.309740   \n",
              "24     212       3          4.266835   \n",
              "25     212     160          4.092270   \n",
              "26     212     281          4.015369   \n",
              "27     212     110          3.941454   \n",
              "28     212     741          3.825574   \n",
              "29     212     229          3.681037   \n",
              "\n",
              "                                              title  \n",
              "0                       Sleepless in Seattle (1993)  \n",
              "1                           Private Benjamin (1980)  \n",
              "2                     Muppet Treasure Island (1996)  \n",
              "3                                    Henry V (1989)  \n",
              "4                       Hudsucker Proxy, The (1994)  \n",
              "5   Seventh Seal, The (Sjunde inseglet, Det) (1957)  \n",
              "6                                      Mimic (1997)  \n",
              "7                                 GoodFellas (1990)  \n",
              "8                                       Babe (1995)  \n",
              "9                                    Aladdin (1992)  \n",
              "10                   Remains of the Day, The (1993)  \n",
              "11                        Young Frankenstein (1974)  \n",
              "12                           Terminator, The (1984)  \n",
              "13                     Pink Floyd - The Wall (1982)  \n",
              "14                        This Is Spinal Tap (1984)  \n",
              "15                           Field of Dreams (1989)  \n",
              "16                                   Sleeper (1973)  \n",
              "17                                    Psycho (1960)  \n",
              "18                          Frighteners, The (1996)  \n",
              "19    Star Trek VI: The Undiscovered Country (1991)  \n",
              "20           Aladdin and the King of Thieves (1996)  \n",
              "21                                  Bad Boys (1995)  \n",
              "22                              Citizen Ruth (1996)  \n",
              "23                                    Priest (1994)  \n",
              "24                                Four Rooms (1995)  \n",
              "25                       Glengarry Glen Ross (1992)  \n",
              "26                           River Wild, The (1994)  \n",
              "27                      Operation Dumbo Drop (1995)  \n",
              "28                          Last Supper, The (1995)  \n",
              "29       Star Trek III: The Search for Spock (1984)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c4027d8-5ec8-4950-b7ae-025d3cfc7074\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userid</th>\n",
              "      <th>itemid</th>\n",
              "      <th>predicted_rating</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>212</td>\n",
              "      <td>88</td>\n",
              "      <td>5.108297</td>\n",
              "      <td>Sleepless in Seattle (1993)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>212</td>\n",
              "      <td>167</td>\n",
              "      <td>5.011518</td>\n",
              "      <td>Private Benjamin (1980)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>212</td>\n",
              "      <td>21</td>\n",
              "      <td>5.011458</td>\n",
              "      <td>Muppet Treasure Island (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>212</td>\n",
              "      <td>190</td>\n",
              "      <td>4.942885</td>\n",
              "      <td>Henry V (1989)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>212</td>\n",
              "      <td>81</td>\n",
              "      <td>4.933844</td>\n",
              "      <td>Hudsucker Proxy, The (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>212</td>\n",
              "      <td>650</td>\n",
              "      <td>4.838254</td>\n",
              "      <td>Seventh Seal, The (Sjunde inseglet, Det) (1957)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>212</td>\n",
              "      <td>264</td>\n",
              "      <td>4.786985</td>\n",
              "      <td>Mimic (1997)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>212</td>\n",
              "      <td>182</td>\n",
              "      <td>4.778395</td>\n",
              "      <td>GoodFellas (1990)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>212</td>\n",
              "      <td>8</td>\n",
              "      <td>4.763397</td>\n",
              "      <td>Babe (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>212</td>\n",
              "      <td>95</td>\n",
              "      <td>4.742200</td>\n",
              "      <td>Aladdin (1992)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>212</td>\n",
              "      <td>86</td>\n",
              "      <td>4.699650</td>\n",
              "      <td>Remains of the Day, The (1993)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>212</td>\n",
              "      <td>208</td>\n",
              "      <td>4.666127</td>\n",
              "      <td>Young Frankenstein (1974)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>212</td>\n",
              "      <td>195</td>\n",
              "      <td>4.665243</td>\n",
              "      <td>Terminator, The (1984)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>212</td>\n",
              "      <td>214</td>\n",
              "      <td>4.634145</td>\n",
              "      <td>Pink Floyd - The Wall (1982)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>212</td>\n",
              "      <td>209</td>\n",
              "      <td>4.632306</td>\n",
              "      <td>This Is Spinal Tap (1984)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>212</td>\n",
              "      <td>215</td>\n",
              "      <td>4.607459</td>\n",
              "      <td>Field of Dreams (1989)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>212</td>\n",
              "      <td>152</td>\n",
              "      <td>4.606413</td>\n",
              "      <td>Sleeper (1973)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>212</td>\n",
              "      <td>185</td>\n",
              "      <td>4.605151</td>\n",
              "      <td>Psycho (1960)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>212</td>\n",
              "      <td>123</td>\n",
              "      <td>4.595540</td>\n",
              "      <td>Frighteners, The (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>212</td>\n",
              "      <td>227</td>\n",
              "      <td>4.564913</td>\n",
              "      <td>Star Trek VI: The Undiscovered Country (1991)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>212</td>\n",
              "      <td>422</td>\n",
              "      <td>4.559592</td>\n",
              "      <td>Aladdin and the King of Thieves (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>212</td>\n",
              "      <td>27</td>\n",
              "      <td>4.556769</td>\n",
              "      <td>Bad Boys (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>212</td>\n",
              "      <td>236</td>\n",
              "      <td>4.315180</td>\n",
              "      <td>Citizen Ruth (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>212</td>\n",
              "      <td>57</td>\n",
              "      <td>4.309740</td>\n",
              "      <td>Priest (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>212</td>\n",
              "      <td>3</td>\n",
              "      <td>4.266835</td>\n",
              "      <td>Four Rooms (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>212</td>\n",
              "      <td>160</td>\n",
              "      <td>4.092270</td>\n",
              "      <td>Glengarry Glen Ross (1992)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>212</td>\n",
              "      <td>281</td>\n",
              "      <td>4.015369</td>\n",
              "      <td>River Wild, The (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>212</td>\n",
              "      <td>110</td>\n",
              "      <td>3.941454</td>\n",
              "      <td>Operation Dumbo Drop (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>212</td>\n",
              "      <td>741</td>\n",
              "      <td>3.825574</td>\n",
              "      <td>Last Supper, The (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>212</td>\n",
              "      <td>229</td>\n",
              "      <td>3.681037</td>\n",
              "      <td>Star Trek III: The Search for Spock (1984)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c4027d8-5ec8-4950-b7ae-025d3cfc7074')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c4027d8-5ec8-4950-b7ae-025d3cfc7074 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c4027d8-5ec8-4950-b7ae-025d3cfc7074');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "user2userRecommendation(212)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkaJ9S48m8mh"
      },
      "source": [
        "Let us make top n recommendation for a given user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNSbxdCSm8mh"
      },
      "source": [
        "#### Evaluation with Mean Absolute Error (MAE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "FwzO2bVnm8mh"
      },
      "outputs": [],
      "source": [
        "from recsys.preprocessing import train_test_split, get_examples\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column='rating')\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)\n",
        "\n",
        "def evaluate(x_test, y_test):\n",
        "    print('Evaluate the model on {} test data ...'.format(x_test.shape[0]))\n",
        "    preds = list(predict(u,i) for (u,i) in x_test)\n",
        "    mae = np.sum(np.absolute(y_test - np.array(preds))) / x_test.shape[0]\n",
        "    print('\\nMAE :', mae)\n",
        "    return mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "5snVsc2Km8mi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c5f836-e784-439e-d234-9896f6ab7057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate the model on 10000 test data ...\n",
            "\n",
            "MAE : 0.7505910931068639\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7505910931068639"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCmePz3Ym8mi"
      },
      "source": [
        "### Summary\n",
        "\n",
        "We have summarised all the steps of building the user-based collaborative filtering into a python class for further user. Click [UserToUser.py](https://github.com/nzhinusoftcm/review-on-collaborative-filtering/blob/master/recsys/memories/UserToUser.py) for more details on the **UserToUser** class definition.\n",
        "\n",
        "#### UserToUser : Evaluation on the ML-100k dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "AoAaZSUKm8mi"
      },
      "outputs": [],
      "source": [
        "from recsys.memories.UserToUser import UserToUser\n",
        "\n",
        "# load ml100k ratings\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "# prepare data\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column='rating')\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "JQWKUfNxm8mi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d30c37-2bc3-4da3-bc7b-c61beb32844e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n"
          ]
        }
      ],
      "source": [
        "# create the user-based CF\n",
        "usertouser = UserToUser(ratings, movies, metric='cosine')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "OIIEQJWMm8mj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819f86c8-5fb5-4419-d9e5-1c9d094d814e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate the model on 10000 test data ...\n",
            "\n",
            "MAE : 0.7505910931068639\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7505910931068639"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "# evaluate the user-based CF on the ml100k test data\n",
        "usertouser.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuZiaXuim8mj"
      },
      "source": [
        "#### Evaluation on the ML-1M dataset (this may take some time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwuYGNB7m8mj",
        "outputId": "eb7c74c5-4062-429e-d0a0-65328674bbd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download data 100.1%\n",
            "Successfully downloaded ml-1m.zip 5917549 bytes.\n",
            "Unzipping the ml-1m.zip zip file ...\n",
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n",
            "==========================\n",
            "Evaluate the model on 100021 test data ...\n",
            "\n",
            "MAE : 0.732267005840993\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.732267005840993"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from recsys.datasets import ml1m\n",
        "from recsys.preprocessing import ids_encoder, get_examples, train_test_split\n",
        "from recsys.memories.UserToUser import UserToUser\n",
        "\n",
        "# memuat data ml1m ratings\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "# prepare data\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column='rating')\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)\n",
        "\n",
        "# create the user-based CF\n",
        "usertouser = UserToUser(ratings, movies, k=20, metric='cosine')\n",
        "\n",
        "# evaluate the user-based CF on the ml1m test data\n",
        "print(\"==========================\")\n",
        "usertouser.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwssygZUm8mk"
      },
      "source": [
        "## Limitations of user-based CF\n",
        "\n",
        "1. <b> Sparsity </b> : In general, users interact with less than 20% of items. This leads the rating matrix to be highly sparse. For example, the movielen-100k contains 100k ratings from 943 users on 1682 items. The pourcentage of sparsity in this case is around $94\\%$. A recommender system based on nearest neighbor algorithms may be unable to make any item recommendations for a particular user. As a result the accuracy of recommendations may be poor <a href=\"https://dl.acm.org/doi/10.1145/371920.372071\">(Sarwar <i>et al.</i> 2001)</a>.\n",
        "\n",
        "2. <b> Stability of user's ratings </b> : As a user rates and re-rates items, their rating vector will change along with their similarity to other users. A user’s neighborhood is determined not only by their ratings but also by the ratings of other users, so their neighborhood can change as a result of new ratings supplied by any user in the system <a href=\"https://dl.acm.org/doi/10.1561/1100000009\">(Michael D. Ekstrand, <i>et al.</i> 2011)</a>.\n",
        "\n",
        "3. <b> Scalability </b> : Due to the non-stability of users ratings, finding similar users in advance is complicated. For this reason, most user-based CF systems find neighborhoods each time predictions or recommendations are needed. However, these are huge computations that grows with both the number of users and the number of items. With millions of users and items, a typical web-based recommender system running existing algorithms will suffer serious scalability concerns <a href=\"https://dl.acm.org/doi/10.1145/371920.372071\">(Sarwar <i>et al.</i> 2001)</a>, <a href=\"https://dl.acm.org/doi/10.1561/1100000009\">(Michael D. Ekstrand, <i>et al.</i> 2011)</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkVJcvj6m8mk"
      },
      "source": [
        "### Item-based CF\n",
        "\n",
        "With Item-based CF, it's possible to compute similarities in advance and use them for online recommendations. This allows the Item-based to be more scalable than the User-based algorithm.\n",
        "\n",
        "Click [here](https://github.com/nzhinusoftcm/review-on-collaborative-filtering/blob/master/3.item-based_collaborative_filtering.ipynb) to go to the Item-based Implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsEjK0D4m8mk"
      },
      "source": [
        "## References\n",
        "\n",
        "1. Herlocker et al. (1999)<a href=\"https://dl.acm.org/doi/10.1145/3130348.3130372\"> An Algorithmic Framework for Performing Collaborative Filtering</a>\n",
        "2. Sarwar et al. (2001) <a href=\"https://dl.acm.org/doi/10.1145/371920.372071\"> Item-based collaborative filtering recommendation algorithms</a> \n",
        "3. Michael D. Ekstrand, et al. (2011). <a href=\"https://dl.acm.org/doi/10.1561/1100000009\"> Collaborative Filtering Recommender Systems</a>\n",
        "4. J. Bobadilla et al. (2013)<a href=\"https://romisatriawahono.net/lecture/rm/survey/information%20retrieval/Bobadilla%20-%20Recommender%20Systems%20-%202013.pdf\"> Recommender systems survey</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYvcBxNcm8ml"
      },
      "source": [
        "## Author\n",
        "\n",
        "[Carmel WENGA](https://www.linkedin.com/in/carmel-wenga-871876178/), <br>\n",
        "PhD student at Université de la Polynésie Française, <br> \n",
        "Applied Machine Learning Research Engineer, <br>\n",
        "[ShoppingList](https://shoppinglist.cm), NzhinuSoft."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qgK07Cpwm8mq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
